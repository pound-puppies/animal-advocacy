{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d0e6c-493f-4d0a-a1d5-3e9003dfdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wrangle as w\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, classification_report\n",
    "\n",
    "#model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b134300-0dab-42ab-8e31-b5c646ae8d3d",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33238931-8ffd-4243-a79a-efaf0981984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.left_join_csv('austin_animal_outcomes.csv', 'austin_animal_intakes.csv', 'merged_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a544c45-1ba7-4280-9c37-f57534c3f73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99607fbc-daac-40f8-a791-a058c5a0bb95",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efd34f-d6af-4406-8f2f-8a5ed57a284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import text, create_engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "####################### Imports ############################\n",
    "\n",
    "                                                        ############### Acquire Functions ###########################\n",
    "\n",
    "def get_aa_data(fn, query, url):\n",
    "    \"\"\"\n",
    "    check if file exists in my local directory, if not, pull from sql db\n",
    "    return dataframe\n",
    "    \"\"\"\n",
    "    if os.path.isfile(fn):\n",
    "        print('csv file found and loaded')\n",
    "        return pd.read_csv(fn, index_col=0)\n",
    "    else:\n",
    "        print('creating df and exporting csv')\n",
    "        df = pd.read_sql(query, url)\n",
    "        df.to_csv(fn)\n",
    "        return df\n",
    "    \n",
    "def get_prep_aa(df):\n",
    "    # made all column names lower case\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "    new_columns = {\n",
    "        'datetime_x': 'outcome_datetime',\n",
    "        'datetime_y': 'intake_datetime',\n",
    "        'monthyear_x': 'outcome_monthyear',\n",
    "        'monthyear_y': 'intake_monthyear',\n",
    "        'name_y': 'name',\n",
    "        'breed_y': 'breed',\n",
    "        'animal type_y': 'species',\n",
    "        'outcome type': 'outcome',\n",
    "        'color_y': 'color',\n",
    "        'sex upon outcome': 'outcome_sex',\n",
    "        'sex upon intake': 'intake_sex',\n",
    "        'intake type': 'intake_type',\n",
    "        'age upon intake': 'intake_age',\n",
    "        'age upon outcome': 'outcome_age',\n",
    "        'date of birth': 'dob',\n",
    "        'intake condition': 'intake_condition',\n",
    "        'found location': 'found_location',\n",
    "        'animal id': 'id'      \n",
    "    }\n",
    "    df = df.rename(columns=new_columns)\n",
    "    #dropped unnecessary column names, outcome subtype, due to having over 119k of 193k rows empty, intake_monthyear, outcome_month_year, animal type_x, are predominantly the same, \n",
    "    columns_to_drop = ['outcome subtype', 'name_x', 'breed_x', 'animal type_x', 'color_x', 'intake_monthyear', 'outcome_monthyear']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # dropping nulls\n",
    "    df.dropna(subset=['intake_sex'], inplace=True)\n",
    "    df.dropna(subset=['outcome'], inplace=True)\n",
    "\n",
    "    # create dates\n",
    "    df['outcome_date'] = pd.to_datetime(df['outcome_datetime']).dt.strftime('%m/%d/%Y').astype(\"datetime64\")\n",
    "    df['intake_date'] = pd.to_datetime(df['intake_datetime']).dt.strftime('%m/%d/%Y').astype(\"datetime64\")\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='%m/%d/%Y')\n",
    "\n",
    "    # create ages\n",
    "    df['intake_age'] = (df.intake_date - df.dob).dt.days\n",
    "    df['outcome_age'] = (df.outcome_date - df.dob).dt.days\n",
    "\n",
    "    # days in center\n",
    "    df[\"tenure_days\"] = (df['outcome_age'] - df['intake_age'] )\n",
    "    # filter weird dates\n",
    "    df = df[df.tenure_days > 0]\n",
    "\n",
    "    # color and intake condition columns\n",
    "    df = transform_color(df)\n",
    "    df = transform_intake_condition(df)\n",
    "\n",
    "    #filtered for cats and dogs\n",
    "    df = df[df['species'].isin(['cat', 'dog'])]\n",
    "    df = df[df['outcome'].isin(['adoption', 'transfer', 'rto-adopt', 'return to owner', 'euthanasia'])]\n",
    "    df = df[df['intake_type'].isin(['stray', 'owner surrender', 'public assist', 'abandoned'])]\n",
    "\n",
    "    # mix breeds columns\n",
    "    df['mix_breeds'] = np.where(df['breed'].str.contains('mix', case=False, na=False), 1, 0)\n",
    "    df['two_breeds'] = np.where(df['breed'].str.contains('/', case=False, na=False), 1, 0)\n",
    "    df['pure_breed'] = np.where(df['breed'].isin(['/', 'mix']), 1, 0)\n",
    "\n",
    "    # if pet has a name 1, if not 0 place in column has_name\n",
    "    df['has_name'] = np.where(df['name'] != 'nan', 1, 0)\n",
    "\n",
    "    # dropping unknown sex from df\n",
    "    df = df[(df.intake_sex != 'unknown') & (df.intake_sex != 'nan')]\n",
    "\n",
    "    # keep these columns\n",
    "    keep_col= ['has_name', 'outcome', 'dob',\n",
    "               'species', 'intake_type', 'intake_condition',\n",
    "               'intake_date', 'outcome_date', 'intake_age',\n",
    "               'outcome_age', 'tenure_days', 'intake_sex',\n",
    "               'breed', 'mix_breeds', 'two_breeds', 'pure_breed',\n",
    "               'primary_color', 'is_tabby', 'mix_color']\n",
    "    df = df[keep_col]\n",
    "\n",
    "    dummies_df = pd.get_dummies(df, columns=['outcome', 'species', 'intake_type',\n",
    "                                             'intake_condition', 'intake_sex', 'primary_color'])\n",
    "    model_df = dummies_df.drop(columns=['dob', 'intake_date', 'outcome_date', 'breed'])\n",
    "    return df, model_df\n",
    "\n",
    "                                #################### Prepare Functions ##########################\n",
    "\n",
    "def transform_intake_condition(df):\n",
    "    \"\"\"\n",
    "    Transforms the intake_condition column of a DataFrame by performing several operations.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing an 'intake_condition' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The transformed DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "    # Change 'Feral', 'Neurologic', 'Behavior', 'Space' to 'mental' category\n",
    "    df['intake_condition'] = df['intake_condition'].replace(['feral', 'neurologic', 'behavior', 'space'], 'mental')\n",
    "\n",
    "    # Set values indicating medical attention\n",
    "    df['intake_condition'] = df['intake_condition'].replace(['nursing', 'neonatal', 'medical', 'pregnant', 'med attn', \n",
    "                                                            'med urgent', 'parvo', 'agonal', 'panleuk'], 'medical attention')\n",
    "\n",
    "    # Drop rows with 'other', 'unknown', and 'nan' values\n",
    "    df = df[df['intake_condition'].isin(['other', 'unknown', 'nan']) == False]\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "def transform_color(df):\n",
    "    \"\"\"\n",
    "    Transforms the color column of a DataFrame by performing several operations.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing a 'color' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The transformed DataFrame with additional columns.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # lowercase everything\n",
    "    df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "    # Add spaces between color names separated by slashes\n",
    "    df['color'] = df['color'].str.replace('/', ' / ')\n",
    "\n",
    "    # Replace color names with their corresponding standard names\n",
    "    replacements = {\n",
    "        'chocolate': 'brown',\n",
    "        'liver': 'brown',\n",
    "        'ruddy': 'brown',\n",
    "        'apricot': 'orange',\n",
    "        'pink': 'red',\n",
    "        'cream': 'white',\n",
    "        'flame point': 'white',\n",
    "        'blue': 'gray',\n",
    "        'silver': 'gray',\n",
    "        'yellow': 'gold',\n",
    "        'torbie': 'tricolor',\n",
    "        'tortie': 'tricolor',\n",
    "        'calico': 'tricolor'\n",
    "    }\n",
    "    df['color'] = df['color'].replace(replacements, regex=True)\n",
    "\n",
    "    # Create new column 'primary_color' with the first color\n",
    "    colors = ['black', 'brown', 'white', 'tan', 'brindle', 'gray', 'fawn', 'red', 'sable', 'buff', 'orange', 'blue',\n",
    "              'tricolor', 'gold', 'cream', 'lynx point', 'seal point', 'agouti', 'lilac point']\n",
    "    for color in colors:\n",
    "        df.loc[df['color'].str.startswith(color), 'primary_color'] = color\n",
    "\n",
    "    # Drop rows with 'unknown' color\n",
    "    df = df[df['color'] != 'unknown']\n",
    "\n",
    "    # Create column indicating if the animal has a tabby pattern\n",
    "    df['is_tabby'] = df['color'].str.contains('tabby').astype(int)\n",
    "\n",
    "    # Create column indicating if the animal has mixed colors\n",
    "    df[\"mix_color\"] = np.where(df['color'].str.contains(r'\\/|tricolor|torbie|tortie'), 1, 0)\n",
    "\n",
    "    df = df.drop(columns=[\"color\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data(df, target_variable):\n",
    "    '''\n",
    "    Takes in two arguments the dataframe name and the (\"target_variable\" - must be in string format) to stratify  and \n",
    "    return train, validate, test subset dataframes will output train, validate, and test in that order.\n",
    "    '''\n",
    "    train, test = train_test_split(df, #first split\n",
    "                                   test_size=.2, \n",
    "                                   random_state=123, \n",
    "                                   stratify= df[target_variable])\n",
    "    train, validate = train_test_split(train, #second split\n",
    "                                    test_size=.25, \n",
    "                                    random_state=123, \n",
    "                                    stratify=train[target_variable])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3147d-e98e-4d0f-83c7-14d5c2a56a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, model_df = w.prep_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0092c-cd1c-4cd6-80a6-1925bbb62d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39334ad4-9362-4ecd-8f79-0e8cfbd0287c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d1dc3-343f-4d70-838d-2a77f2214d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be79585-f4e3-4a76-bffb-3f89a69fd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28abc9d-1643-441d-b361-c0c30db9186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.breed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881d917-444b-4f2f-b75f-3b5d0eb23547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.color.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bed0b-0021-4df7-9f38-1a634ab84ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af8b38-8bed-4cc6-a188-ad3bddaf3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validate,test = w.split_data(df, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3df75-b59f-4d1a-9306-f6da7193b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73557e8-8213-43f9-872e-ed807f591fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1967324-16f6-412c-aeb3-a4ff0453559a",
   "metadata": {},
   "source": [
    "# Question and Hypothesis Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be7865-6bc0-4ff4-96c1-adfbd638a83d",
   "metadata": {},
   "source": [
    "Does Tenure have a correlation to adoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cb320-d5e3-4b7e-903a-7f71d11cb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tenure_ttest(data):\n",
    "    '''\n",
    "    runs a Ttest for Tenure county vs Outcome\n",
    "    '''\n",
    "    x = data['outcome_adoption']\n",
    "    y = data['tenure_days']\n",
    "    # Perform t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(x, y)\n",
    "    # Decide whether to reject the null hypothesis\n",
    "    alpha = 0.05\n",
    "    if p_value >= alpha:\n",
    "        decision = \"Fail to Reject Null Hypothesis\"\n",
    "    else:\n",
    "        decision = \"Reject Null Hypothesis\"\n",
    "# Create a DataFrame to store the results\n",
    "    results = pd.DataFrame({\n",
    "        'T-Statistic': [t_statistic],\n",
    "        'P-Value': [p_value],\n",
    "        'Decision': [decision]})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427a1b7-5739-45c6-b460-4b3cbe3f2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_df.tenure_days = model_df.tenure_days.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e1061-4b70-40b9-a6b9-a472eb7aacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.tenure_days.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e2bb0-ff01-4333-90cd-b42bc547004c",
   "metadata": {},
   "source": [
    "##### Hypothisis: County\\n\",\n",
    "$H_0$ : Outcome is independent of tenure <br>\\\n",
    "$H_a$ : Outcome is not independent of tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3069868-3397-4fd4-8848-7a1cf75e7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.stats as stats\n",
    "\n",
    "#run_tenure_ttest(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbc29a-7616-4dda-b8f5-5fa5786316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.box(model_df, x=\"outcome_adoption\", y=\"tenure_days\", notched=True)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0210b-05f1-4db4-a0eb-1b5b9f3a2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_df.tenure_days.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ee454-08cd-471e-b2fc-e491f0dbe2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fdf98ed-dcd0-475f-902d-c988eb6a730c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37469a49-f941-4ae6-aa8a-592dd732dc9c",
   "metadata": {},
   "source": [
    "Tenure wont work due to lack of data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7314dc8-f005-47db-9552-0795d8aadf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a4f15-e3d6-48ae-85e2-01645b591f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024756c-d805-457e-bae3-e8dcb8d92ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992070f-9529-4a3c-a8f2-1cedc5facd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb800df-6ebf-4423-adfd-03c3a7b9ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85269e6-b7e5-443c-a004-92d0ac0d386c",
   "metadata": {},
   "source": [
    "# Question and Hypothesis Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e94d8c-60dc-4548-89e7-3198c23170c4",
   "metadata": {},
   "source": [
    "Is there a corolation between intake_sex and outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811c0cf-b059-4ae3-92a2-0c565799e753",
   "metadata": {},
   "source": [
    "##### Hypothisis: County\\n\",\n",
    "$H_0$ : Outcome is independent of sex <br>\\\n",
    "$H_a$ : Outcome is not independent of sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38003905-7924-48a2-b19f-3e89aba68154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "#df = train\n",
    "#grouped_data = df.groupby([\"sex\", \"outcome\"]).size().reset_index(name=\"count\")\n",
    "#\n",
    "#fig = px.bar(grouped_data, x=\"sex\", y=\"count\", color=\"outcome\", barmode=\"group\")\n",
    "#fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ff02a-00d8-4c1c-b655-48d879928dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(train['sex'], train['outcome'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490dfd0-c166-46ea-a3c9-702b271e8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff10f7-71c6-49ee-8c95-8b180a9e6e62",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7074b29-20e8-4a75-b873-931190522c31",
   "metadata": {},
   "source": [
    "Ther is a relationship here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098adb44-18ed-47c8-ae5f-f765f4e3ce74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698958d-a6dc-4f2e-91ce-b89dea00842d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d602fb-6d06-407c-bf72-afc1829bde73",
   "metadata": {},
   "source": [
    "# Question and Hypothesis Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d9316-945c-4bb7-a9b5-25daa8844ee5",
   "metadata": {},
   "source": [
    "are taby cats more likely to get adopted than non taby cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13777fc7-b5be-4ff4-8c95-2fc5e9c85958",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = train[train.species == 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ecc50-449f-4257-a84f-2af6f51cacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.is_tabby.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb49042-2d76-41eb-9a2f-d464a3f272ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.is_tabby.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b444ea-d88d-4b9a-9663-3cd2ac585757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grouped_data = cats.groupby([\"is_tabby\", \"outcome\"]).size().reset_index(name=\"count\")\n",
    "#\n",
    "#fig = px.bar(grouped_data, x=\"is_tabby\", y=\"count\", color=\"outcome\", barmode=\"group\")\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80533ab6-08bd-4526-bab9-33cd2967aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table_tabby = pd.crosstab(cats['is_tabby'], train['outcome'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table_tabby)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989d4ab-3310-4965-a4f0-ff6ac469bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table_tabby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4786e26-d8e6-4cdf-af56-2379451d48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "6033/cats.is_tabby.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b03d28-6a86-44ec-8ac6-05c2906eeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "902/cats.is_tabby.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c086b9-9027-4684-a5e4-eb6fad90dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "5298/cats.is_tabby.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90075bfc-f6e2-47af-8f30-b17b4256c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "690/cats.is_tabby.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b215d-dea5-4276-920c-28ed20f8e0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a9dd157-18a4-4e00-8450-9be9c9edcb7a",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14c4af-d6ec-44f5-bff5-fb552faa0d4e",
   "metadata": {},
   "source": [
    "the outcome for cats based on it being a tabby or not seems to propotionate despite CHI2 indicating some relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19806dc-2719-41b2-825b-8eb801f9b339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6bd66-d67c-49a2-aa46-f9f62ab918fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ba80b6-a3dc-4851-a699-fed3424f08dc",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdad32-f20f-44c5-bef0-c3c611304444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcccb33-e64a-4663-a5f0-fabda7751b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(y_train):\n",
    "    '''\n",
    "    this function returns a baseline for accuracy\n",
    "    '''\n",
    "    baseline_prediction = y_train.mode()\n",
    "    # Predict the majority class in the training set\n",
    "    baseline_pred = [baseline_prediction] * len(y_train)\n",
    "    accuracy = accuracy_score(y_train, baseline_pred)\n",
    "    baseline_results = {'Baseline': [baseline_prediction],'Metric': ['Accuracy'], 'Score': [accuracy]}\n",
    "    baseline_df = pd.DataFrame(data=baseline_results)\n",
    "    return baseline_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fdee61-93cf-42b4-987c-a76bfb9c1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating X,y\n",
    "def get_xy():\n",
    "    '''\n",
    "    This function generates X and y for train, validate, and test\n",
    "    '''\n",
    "    # Acquiring data\n",
    "    df = w.left_join_csv('austin_animal_outcomes.csv', 'austin_animal_intakes.csv', 'merged_data.csv')\n",
    "    # Running preperation \n",
    "    df, model_df = w.prep_df(df)\n",
    "    # Split\n",
    "    train, validate, test = w.split_data(model_df,'outcome')\n",
    "    # create X & y version of train, where y is a series with just the target variable and X are all the features.    \n",
    "    X_train = train.drop(['outcome'], axis=1)\n",
    "    y_train = train.outcome\n",
    "    X_validate = validate.drop(['outcome'], axis=1)\n",
    "    y_validate = validate.outcome\n",
    "    X_test = test.drop(['outcome'], axis=1)\n",
    "    y_test = test.outcome\n",
    "    return X_train,y_train,X_validate,y_validate,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ceb1df-0037-4b56-931e-1b371ea0324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2dafcc-f325-4206-9bca-26e1395d735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_models(seed=123):\n",
    "    '''\n",
    "    Create a list of machine learning models.\n",
    "            Parameters:\n",
    "                    seed (integer): random seed of the models\n",
    "            Returns:\n",
    "                    models (list): list containing the models\n",
    "    This includes best fit hyperparamaenters                \n",
    "    '''\n",
    "    models = []\n",
    "    models.append(('k_nearest_neighbors', KNeighborsClassifier(n_neighbors=100)))\n",
    "    models.append(('logistic_regression', LogisticRegression(random_state=seed)))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=3,min_samples_split=4,random_state=seed)))\n",
    "    models.append(('random_forest', RandomForestClassifier(max_depth=3,random_state=seed)))\n",
    "    models.append(('support_vector_machine', SVC(random_state=seed)))\n",
    "    models.append(('naive_bayes', GaussianNB()))\n",
    "    models.append(('gradient_boosting', GradientBoostingClassifier(random_state=seed)))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba2fac-6b3c-4ead-b9b5-05b7ad69122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    # create models list\n",
    "    models = create_models(seed=123)\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = get_xy()\n",
    "    # initialize results dataframe\n",
    "    results = pd.DataFrame(columns=['model', 'set', 'accuracy', 'recall'])\n",
    "    \n",
    "    # loop through models and fit/predict on train and validate sets\n",
    "    for name, model in models:\n",
    "        # fit the model with the training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # make predictions with the training data\n",
    "        train_predictions = model.predict(X_train)\n",
    "        \n",
    "        # calculate training accuracy, recall, and precision\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
    "        train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
    "        \n",
    "        # make predictions with the validation data\n",
    "        val_predictions = model.predict(X_validate)\n",
    "        \n",
    "        # calculate validation accuracy, recall, and precision\n",
    "        val_accuracy = accuracy_score(y_validate, val_predictions)\n",
    "        val_recall = recall_score(y_validate, val_predictions, average='weighted')\n",
    "        val_precision = precision_score(y_validate, val_predictions, average='weighted')\n",
    "\n",
    "        \n",
    "        # append results to dataframe\n",
    "        results = results.append({'model': name, 'set': 'train', 'accuracy': train_accuracy, 'recall': train_recall, 'precision' : train_precision},ignore_index=True)\n",
    "        results = results.append({'model': name, 'set': 'validate', 'accuracy': val_accuracy, 'recall': val_recall, 'precision' : val_precision}, ignore_index=True)\n",
    "  \n",
    "\n",
    "        '''\n",
    "        this section left in case I want to return to printed format rather than data frame\n",
    "        # print classifier accuracy and recall\n",
    "        print('Classifier: {}, Train Accuracy: {}, Train Recall: {}, Validation Accuracy: {}, Validation Recall: {}'.format(name, train_accuracy, train_recall, val_accuracy, val_recall))\n",
    "        '''\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6a683-66ec-47f6-94e3-57ab11c9a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5a032-bc54-4888-b480-3fa6ae6d6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_baseline(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9035e-6939-43a9-a1b6-ea17d7b1920c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
